"""
Vulnerability Analyzer - Identify and Score Vulnerabilities

Analyzes attack dataset to identify vulnerabilities in cryptographic algorithms.
"""

import pandas as pd
import logging
from typing import Dict, List, Any

logger = logging.getLogger(__name__)


class VulnerabilityAnalyzer:
    """
    Analyzer for identifying and scoring algorithm vulnerabilities
    """
    
    # Category weights for vulnerability scoring
    CATEGORY_WEIGHTS = {
        'brute_force': 1.0,
        'statistical': 0.8,
        'cryptanalysis': 1.5,
        'algebraic': 1.2,
        'side_channel': 0.9,
        'quantum': 0.5,
        'lattice': 1.1,
        'hash_collision': 1.0,
        'implementation_flaw': 0.7,
    }
    
    # Severity multipliers
    SEVERITY_MULTIPLIERS = {
        'critical': 3.0,
        'high': 2.0,
        'medium': 1.0,
        'low': 0.3,
    }
    
    def __init__(self, attack_data: pd.DataFrame):
        """
        Initialize with attack dataset
        
        Args:
            attack_data: DataFrame containing attack execution records
        """
        self.attack_data = attack_data
        logger.info(f"Initialized VulnerabilityAnalyzer with {len(attack_data)} attack records")
        
    def analyze_algorithm(self, algorithm: str) -> Dict[str, Any]:
        """
        Analyze single algorithm for vulnerabilities
        
        Args:
            algorithm: Algorithm name to analyze
            
        Returns:
            Dictionary containing vulnerability analysis
        """
        algo_data = self.attack_data[self.attack_data['algorithm_name'] == algorithm]
        
        if len(algo_data) == 0:
            logger.warning(f"No data found for algorithm: {algorithm}")
            return {}
            
        total_attacks = len(algo_data)
        successful_attacks = algo_data['attack_success'].sum()
        success_rate = successful_attacks / total_attacks if total_attacks > 0 else 0.0
        
        vuln_score = self.calculate_vulnerability_score(algorithm)
        severity = self._determine_severity(vuln_score)
        
        # Find critical vulnerabilities
        critical_vulns = self._identify_critical_vulnerabilities(algo_data)
        
        result = {
            'algorithm': algorithm,
            'vulnerability_score': vuln_score,
            'severity': severity,
            'successful_attacks': int(successful_attacks),
            'total_attacks': total_attacks,
            'success_rate': float(success_rate),
            'critical_vulnerabilities': critical_vulns,
            'recommendations': self._generate_recommendations(algorithm, vuln_score, severity)
        }
        
        return result
        
    def analyze_all_algorithms(self) -> pd.DataFrame:
        """
        Analyze all algorithms in dataset
        
        Returns:
            DataFrame with vulnerability analysis for all algorithms
        """
        algorithms = self.attack_data['algorithm_name'].unique()
        results = []
        
        logger.info(f"Analyzing {len(algorithms)} algorithms...")
        
        for algo in algorithms:
            result = self.analyze_algorithm(algo)
            if result:
                results.append(result)
                
        df = pd.DataFrame(results)
        logger.info(f"Completed analysis of {len(results)} algorithms")
        
        return df
        
    def calculate_vulnerability_score(self, algorithm: str) -> float:
        """
        Calculate composite vulnerability score (0-100)
        
        Args:
            algorithm: Algorithm name
            
        Returns:
            Vulnerability score (0=secure, 100=highly vulnerable)
        """
        algo_data = self.attack_data[self.attack_data['algorithm_name'] == algorithm]
        
        if len(algo_data) == 0:
            return 0.0
            
        total_score = 0.0
        total_weight = 0.0
        
        # Group by attack category
        for category, weight in self.CATEGORY_WEIGHTS.items():
            category_data = algo_data[algo_data['attack_category'] == category]
            
            if len(category_data) == 0:
                continue
                
            category_success_rate = category_data['attack_success'].mean()
            
            # Calculate weighted contribution
            contribution = category_success_rate * weight * 100
            total_score += contribution
            total_weight += weight
            
        # Normalize
        vuln_score = min(100.0, total_score / total_weight if total_weight > 0 else 0.0)
        
        return round(vuln_score, 2)
        
    def identify_critical_vulnerabilities(self) -> List[Dict[str, Any]]:
        """
        Find critical vulnerabilities across all algorithms
        
        Returns:
            List of critical vulnerability records
        """
        # Filter for successful attacks with high confidence
        critical = self.attack_data[
            (self.attack_data['attack_success'] == True) &
            (self.attack_data['confidence_score'] >= 0.7) &
            (self.attack_data['vulnerability_detected'] == True)
        ]
        
        results = []
        for _, row in critical.iterrows():
            results.append({
                'algorithm': row['algorithm_name'],
                'attack': row['attack_name'],
                'category': row['attack_category'],
                'confidence': row['confidence_score'],
                'severity': row.get('severity_level', 'unknown'),
            })
            
        return results
        
    def generate_vulnerability_report(self) -> Dict[str, Any]:
        """
        Generate comprehensive vulnerability report
        
        Returns:
            Complete vulnerability analysis report
        """
        all_vulns = self.analyze_all_algorithms()
        
        report = {
            'report_version': '1.0',
            'total_algorithms': len(all_vulns),
            'critical_count': len(all_vulns[all_vulns['severity'] == 'critical']),
            'high_count': len(all_vulns[all_vulns['severity'] == 'high']),
            'medium_count': len(all_vulns[all_vulns['severity'] == 'medium']),
            'low_count': len(all_vulns[all_vulns['severity'] == 'low']),
            'vulnerabilities_by_algorithm': all_vulns.to_dict('records'),
            'critical_vulnerabilities': self.identify_critical_vulnerabilities(),
        }
        
        logger.info(f"Generated vulnerability report: {report['critical_count']} critical, "
                   f"{report['high_count']} high vulnerabilities")
        
        return report
        
    def _identify_critical_vulnerabilities(self, algo_data: pd.DataFrame) -> List[Dict]:
        """Helper to identify critical vulnerabilities for single algorithm"""
        critical = algo_data[
            (algo_data['attack_success'] == True) &
            (algo_data['confidence_score'] >= 0.7)
        ]
        
        results = []
        for _, row in critical.head(5).iterrows():  # Top 5
            results.append({
                'attack': row['attack_name'],
                'success_rate': float(row['confidence_score']),
                'category': row['attack_category'],
            })
            
        return results
        
    def _determine_severity(self, vuln_score: float) -> str:
        """Determine severity level from vulnerability score"""
        if vuln_score >= 70:
            return 'critical'
        elif vuln_score >= 50:
            return 'high'
        elif vuln_score >= 30:
            return 'medium'
        else:
            return 'low'
            
    def _generate_recommendations(self, algorithm: str, vuln_score: float, severity: str) -> List[str]:
        """Generate security recommendations"""
        recommendations = []
        
        if severity == 'critical':
            recommendations.append(f"Discontinue use of {algorithm} immediately")
            recommendations.append("Migrate to a more secure algorithm")
        elif severity == 'high':
            recommendations.append(f"Use {algorithm} with caution")
            recommendations.append("Consider migrating to more secure alternatives")
        elif severity == 'medium':
            recommendations.append(f"{algorithm} is acceptable for non-critical use cases")
            recommendations.append("Monitor for new vulnerabilities")
        else:
            recommendations.append(f"{algorithm} appears secure against tested attacks")
            
        return recommendations

